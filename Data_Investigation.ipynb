{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(hep.style.ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/eos/home-m/matheus/output_AQAg/\" # Caminho comum para todos os arquivos .h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função que abre os arquivos .h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$M_{x} = \\sqrt{s}\\sqrt{\\xi_{\\text{proton}_{1}}\\xi_{\\text{proton}_{2}}}$ \n",
    "\n",
    "onde $\\sqrt{s}=13000$ é a energia do centro de massa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ Y_{x} = \\dfrac{1}{2} \\; \\ln{ \\left(\\dfrac{\\xi_{\\text{proton}_{1}}}{\\xi_{\\text{proton}_{2}}}\\right) } $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file( file ):\n",
    "    df = None\n",
    "    with h5py.File( file , 'r' ) as f:\n",
    "        dset = f['dados']\n",
    "        #print ( 'antes do corte nos xis:', dset.shape )\n",
    "        #print ( dset[:,:] )\n",
    "        array = np.array( dset )\n",
    "        array_cut = (array[:,0] > 600) & (array[:,1] > 200) & (array[:,2] > 2) & (array[:,3] > 2) & (array[:,4] > 200) & (array[:,5] < 2.4) & (array[:,7] < 0.6) & (array[:,8] > 40) & (array[:,9] > 53)  & (array[:,10] < 2.4) # Corte no xi1 e no xi2\n",
    "        #array_cut = (array[:,5] <= 2.4) & (array[:,10] <= 2.4) & (array[:,8] >= 40) & (array[:,9] >= 53) & (array[:,4] >= 200)\n",
    "        DataSet_ = array[array_cut]\n",
    "        arrau_cut_xi = (DataSet_[:,14] > 0.04) & (DataSet_[:,15] > 0.04) & (DataSet_[:,14] < 0.111) & (DataSet_[:,15] < 0.138)        \n",
    "        DataSet_ = DataSet_[arrau_cut_xi]\n",
    "        #DataSet_ = array\n",
    "        Mx = 13000 * ( np.sqrt( DataSet_[:,14] * DataSet_[:,15] ) )\n",
    "        Yx = 0.5 * ( np.log( DataSet_[:,15] / DataSet_[:,14] ) )\n",
    "        Mww_Mxx =  DataSet_[:,0] / Mx \n",
    "        Yww_Yx = DataSet_[:,13] - Yx\n",
    "        DataSet = np.concatenate( ( DataSet_, Mx.reshape(-1,1), Yx.reshape(-1,1), Mww_Mxx.reshape(-1,1), Yww_Yx.reshape(-1,1) ), axis = 1 )        \n",
    "        #mask = np.any( np.isnan( DataSet ) , axis = 1 )\n",
    "        #print(DataSet.shape)\n",
    "        #print( 'Depois do corte nos xis:', DataSet.shape)\n",
    "        MultiRP = ( DataSet[:,24] == 1 ) & ( DataSet[:,25] == 1 )\n",
    "        print( 'MultiRP Events :: ', DataSet[ MultiRP ].shape )\n",
    "        return DataSet[ MultiRP ]\n",
    "        return DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Luminosidade Integrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SingleMuon_Run2016B = 4.55\n",
    "SingleMuon_Run2016C = 1.59\n",
    "SingleMuon_Run2016G = 3.65\n",
    "Luminosidade        = SingleMuon_Run2016B + SingleMuon_Run2016C + SingleMuon_Run2016G "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculando as Eficiências "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.22/06\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "pwd_effi = '/eos/home-m/matheus/SWAN_projects/Acoplamento_Quartico_Anomalo/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eficiência dos Prótons para o Signal\n",
    "\n",
    "def EffiProtonSignal( Dataset ):\n",
    "    \n",
    "    f_SF_Prot_POG = ROOT.TFile.Open( pwd_effi + \"PreliminaryEfficiencies_July132020_1D2DMultiTrack.root\")\n",
    "\n",
    "    RadDam_45_F_B = f_SF_Prot_POG.Get(\"Strips/2016/2016B/h45_2016B_RP3_all_2D\")\n",
    "    RadDam_45_N_B = f_SF_Prot_POG.Get(\"Strips/2016/2016B/h45_2016B_RP2_all_2D\")\n",
    "    RadDam_45_F_C = f_SF_Prot_POG.Get(\"Strips/2016/2016C/h45_2016C_RP3_all_2D\")\n",
    "    RadDam_45_N_C = f_SF_Prot_POG.Get(\"Strips/2016/2016C/h45_2016C_RP2_all_2D\")\n",
    "    RadDam_45_F_G = f_SF_Prot_POG.Get(\"Strips/2016/2016G/h45_2016G_RP3_all_2D\")\n",
    "    RadDam_45_N_G = f_SF_Prot_POG.Get(\"Strips/2016/2016G/h45_2016G_RP2_all_2D\")\n",
    "    RadDam_56_F_B = f_SF_Prot_POG.Get(\"Strips/2016/2016B/h56_2016B_RP103_all_2D\")\n",
    "    RadDam_56_N_B = f_SF_Prot_POG.Get(\"Strips/2016/2016B/h56_2016B_RP102_all_2D\")\n",
    "    RadDam_56_F_C = f_SF_Prot_POG.Get(\"Strips/2016/2016C/h56_2016C_RP103_all_2D\")\n",
    "    RadDam_56_N_C = f_SF_Prot_POG.Get(\"Strips/2016/2016C/h56_2016C_RP102_all_2D\")\n",
    "    RadDam_56_F_G = f_SF_Prot_POG.Get(\"Strips/2016/2016G/h56_2016G_RP103_all_2D\")\n",
    "    RadDam_56_N_G = f_SF_Prot_POG.Get(\"Strips/2016/2016G/h56_2016G_RP102_all_2D\")\n",
    "\n",
    "    multitrack_45_F_B = f_SF_Prot_POG.Get(\"Strips/2016/2016B/h45multitrackeff_2016B_avg_RP3\")\n",
    "    multitrack_45_F_C = f_SF_Prot_POG.Get(\"Strips/2016/2016C/h45multitrackeff_2016C_avg_RP3\")\n",
    "    multitrack_45_F_G = f_SF_Prot_POG.Get(\"Strips/2016/2016G/h45multitrackeff_2016G_avg_RP3\")\n",
    "    multitrack_45_N_B = f_SF_Prot_POG.Get(\"Strips/2016/2016B/h45multitrackeff_2016B_avg_RP2\")\n",
    "    multitrack_45_N_C = f_SF_Prot_POG.Get(\"Strips/2016/2016C/h45multitrackeff_2016C_avg_RP2\")\n",
    "    multitrack_45_N_G = f_SF_Prot_POG.Get(\"Strips/2016/2016G/h45multitrackeff_2016G_avg_RP2\")\n",
    "    multitrack_56_F_B = f_SF_Prot_POG.Get(\"Strips/2016/2016B/h56multitrackeff_2016B_avg_RP103\")\n",
    "    multitrack_56_F_C = f_SF_Prot_POG.Get(\"Strips/2016/2016C/h56multitrackeff_2016C_avg_RP103\")\n",
    "    multitrack_56_F_G = f_SF_Prot_POG.Get(\"Strips/2016/2016G/h56multitrackeff_2016G_avg_RP103\")\n",
    "    multitrack_56_N_B = f_SF_Prot_POG.Get(\"Strips/2016/2016B/h56multitrackeff_2016B_avg_RP102\")\n",
    "    multitrack_56_N_C = f_SF_Prot_POG.Get(\"Strips/2016/2016C/h56multitrackeff_2016C_avg_RP102\")\n",
    "    multitrack_56_N_G = f_SF_Prot_POG.Get(\"Strips/2016/2016G/h56multitrackeff_2016G_avg_RP102\")\n",
    "    \n",
    "    \n",
    "    weigth_multitrack_45_F_B = multitrack_45_F_B.GetBinContent(1);\n",
    "    weigth_multitrack_45_F_C = multitrack_45_F_C.GetBinContent(1);\n",
    "    weigth_multitrack_45_F_G = multitrack_45_F_G.GetBinContent(1);\n",
    "    weigth_multitrack_45_N_B = multitrack_45_N_B.GetBinContent(1);\n",
    "    weigth_multitrack_45_N_C = multitrack_45_N_C.GetBinContent(1);\n",
    "    weigth_multitrack_45_N_G = multitrack_45_N_G.GetBinContent(1);\n",
    "    weigth_multitrack_56_F_B = multitrack_56_F_B.GetBinContent(1);\n",
    "    weigth_multitrack_56_F_C = multitrack_56_F_C.GetBinContent(1);\n",
    "    weigth_multitrack_56_F_G = multitrack_56_F_G.GetBinContent(1);\n",
    "    weigth_multitrack_56_N_B = multitrack_56_N_B.GetBinContent(1);\n",
    "    weigth_multitrack_56_N_C = multitrack_56_N_C.GetBinContent(1);\n",
    "    weigth_multitrack_56_N_G = multitrack_56_N_G.GetBinContent(1);\n",
    "    \n",
    "    \n",
    "    w_raddam_45_Multi_B_N = []\n",
    "    w_raddam_45_Multi_C_N = []\n",
    "    w_raddam_45_Multi_G_N = []\n",
    "    w_raddam_45_Multi_B_F = []\n",
    "    w_raddam_45_Multi_C_F = []\n",
    "    w_raddam_45_Multi_G_F = []\n",
    "\n",
    "    for i in range(0, len( Dataset ) ):\n",
    "        if [ Dataset[:,22] == 0 ][0][i] and [ Dataset[:,14] <= 0.111 ][0][i] and [ Dataset[:,15] >= 0.04 ][0][i] : \n",
    "            w_raddam_45_Multi_B_N.append( RadDam_45_N_B.GetBinContent( RadDam_45_N_B.GetXaxis().FindBin(Dataset[:,26][i] ), RadDam_45_N_B.GetYaxis().FindBin( Dataset[:,28][i] ) ) )\n",
    "            w_raddam_45_Multi_C_N.append( RadDam_45_N_C.GetBinContent( RadDam_45_N_C.GetXaxis().FindBin(Dataset[:,26][i] ), RadDam_45_N_C.GetYaxis().FindBin( Dataset[:,28][i] ) ) )\n",
    "            w_raddam_45_Multi_G_N.append( RadDam_45_N_G.GetBinContent( RadDam_45_N_G.GetXaxis().FindBin(Dataset[:,26][i] ), RadDam_45_N_G.GetYaxis().FindBin( Dataset[:,28][i] ) ) )\n",
    "            w_raddam_45_Multi_B_F.append( RadDam_45_F_B.GetBinContent( RadDam_45_F_B.GetXaxis().FindBin(Dataset[:,30][i] ), RadDam_45_F_B.GetYaxis().FindBin( Dataset[:,32][i] ) ) )\n",
    "            w_raddam_45_Multi_C_F.append( RadDam_45_F_C.GetBinContent( RadDam_45_F_C.GetXaxis().FindBin(Dataset[:,30][i] ), RadDam_45_F_C.GetYaxis().FindBin( Dataset[:,32][i] ) ) )            \n",
    "            w_raddam_45_Multi_G_F.append( RadDam_45_F_G.GetBinContent( RadDam_45_F_G.GetXaxis().FindBin(Dataset[:,30][i] ), RadDam_45_F_G.GetYaxis().FindBin( Dataset[:,32][i] ) ) )  \n",
    "    \n",
    "    \n",
    "    \n",
    "    w_raddam_45_Multi = ((4.55/9.79)*np.array(w_raddam_45_Multi_B_N)+(1.59/9.79)*np.array(w_raddam_45_Multi_C_N)+(3.65/9.79)*np.array(w_raddam_45_Multi_G_N))*((4.55/9.79)*np.array(w_raddam_45_Multi_B_F)+(1.59/9.79)*np.array(w_raddam_45_Multi_C_F)+(3.65/9.79)*np.array(w_raddam_45_Multi_G_F) )        \n",
    "\n",
    "    w_raddam_56_Multi_B_N = []\n",
    "    w_raddam_56_Multi_C_N = []\n",
    "    w_raddam_56_Multi_G_N = []\n",
    "    w_raddam_56_Multi_B_F = []\n",
    "    w_raddam_56_Multi_C_F = []\n",
    "    w_raddam_56_Multi_G_F = []\n",
    "\n",
    "    for i in range(0, len( Dataset ) ):\n",
    "        if [ Dataset[:,23] == 1 ][0][i] and [ Dataset[:,14] <= 0.111 ][0][i] and [ Dataset[:,15] >= 0.04 ][0][i]: \n",
    "            w_raddam_56_Multi_B_N.append( RadDam_56_N_B.GetBinContent( RadDam_56_N_B.GetXaxis().FindBin(Dataset[:,27][i] ), RadDam_56_N_B.GetYaxis().FindBin( Dataset[:,29][i] ) ) )\n",
    "            w_raddam_56_Multi_C_N.append( RadDam_56_N_C.GetBinContent( RadDam_56_N_C.GetXaxis().FindBin(Dataset[:,27][i] ), RadDam_56_N_C.GetYaxis().FindBin( Dataset[:,29][i] ) ) )\n",
    "            w_raddam_56_Multi_G_N.append( RadDam_56_N_G.GetBinContent( RadDam_56_N_G.GetXaxis().FindBin(Dataset[:,27][i] ), RadDam_56_N_G.GetYaxis().FindBin( Dataset[:,29][i] ) ) )\n",
    "            w_raddam_56_Multi_B_F.append( RadDam_56_F_B.GetBinContent( RadDam_56_F_B.GetXaxis().FindBin(Dataset[:,31][i] ), RadDam_56_F_B.GetYaxis().FindBin( Dataset[:,33][i] ) ) )\n",
    "            w_raddam_56_Multi_C_F.append( RadDam_56_F_C.GetBinContent( RadDam_56_F_C.GetXaxis().FindBin(Dataset[:,31][i] ), RadDam_56_F_C.GetYaxis().FindBin( Dataset[:,33][i] ) ) )            \n",
    "            w_raddam_56_Multi_G_F.append( RadDam_56_F_G.GetBinContent( RadDam_56_F_G.GetXaxis().FindBin(Dataset[:,31][i] ), RadDam_56_F_G.GetYaxis().FindBin( Dataset[:,33][i] ) ) )  \n",
    "    \n",
    "    \n",
    "    w_raddam_56_Multi = ( (4.55/9.79)*np.array(w_raddam_56_Multi_B_N)+(1.59/9.79)*np.array(w_raddam_56_Multi_C_N)+(3.65/9.79)*np.array(w_raddam_56_Multi_G_N))*((4.55/9.79)*np.array(w_raddam_56_Multi_B_F)+(1.59/9.79)*np.array(w_raddam_56_Multi_C_F)+(3.65/9.79)*np.array(w_raddam_56_Multi_G_F) )        \n",
    "    \n",
    "    \n",
    "    weigth_45_N = weigth_multitrack_45_N_B*(4.55/9.79) + weigth_multitrack_45_N_C*(1.59/9.79) + weigth_multitrack_45_N_G*(3.65/9.79);\n",
    "    weigth_45_F = weigth_multitrack_45_F_B*(4.55/9.79) + weigth_multitrack_45_F_C*(1.59/9.79) + weigth_multitrack_45_F_G*(3.65/9.79);\n",
    "    weigth_45 = (weigth_45_N+weigth_45_F)/2;\n",
    "    weigth_56_N = weigth_multitrack_56_N_B*(4.55/9.79) + weigth_multitrack_56_N_C*(1.59/9.79) + weigth_multitrack_56_N_G*(3.65/9.79);\n",
    "    weigth_56_F = weigth_multitrack_56_F_B*(4.55/9.79) + weigth_multitrack_56_F_C*(1.59/9.79) + weigth_multitrack_56_F_G*(3.65/9.79);\n",
    "    weigth_56 = (weigth_56_N+weigth_56_F)/2;\n",
    "    return w_raddam_45_Multi * weigth_45 * w_raddam_56_Multi * weigth_56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EfficienciesStudies( DataSet ):\n",
    "    \n",
    "    # Muon Efficiency\n",
    "    f_SF_ID_BC = ROOT.TFile.Open(pwd_effi + \"EfficienciesStudies_2016_legacy_rereco_rootfiles_RunBCDEF_SF_ID.root\")\n",
    "    f_SF_ISO_BC = ROOT.TFile.Open(pwd_effi +  \"EfficienciesStudies_2016_legacy_rereco_rootfiles_RunBCDEF_SF_ISO.root\" )\n",
    "    f_SF_trg_BC = ROOT.TFile.Open(pwd_effi +  \"EfficienciesAndSF_trg_RunBtoF.root\" )\n",
    "    f_SF_ID_G = ROOT.TFile.Open(pwd_effi + \"EfficienciesStudies_2016_legacy_rereco_rootfiles_RunGH_SF_ID.root\")\n",
    "    f_SF_ISO_G = ROOT.TFile.Open(pwd_effi + \"EfficienciesStudies_2016_legacy_rereco_rootfiles_RunGH_SF_ISO.root\")\n",
    "    f_SF_trg_G = ROOT.TFile.Open(pwd_effi + \"EfficienciesAndSF_trg_RunGH.root\")\n",
    "    '''\n",
    "    h_SF_ID_BC = ROOT.TH2D()\n",
    "    h_SF_ISO_BC = ROOT.TH2D()\n",
    "    h_SF_TRG_BC = ROOT.TH2D()\n",
    "    h_SF_ID_G = ROOT.TH2D()\n",
    "    h_SF_ISO_G = ROOT.TH2D()\n",
    "    h_SF_TRG_G = ROOT.TH2D()\n",
    "    '''\n",
    "    h_SF_ID_BC = f_SF_ID_BC.Get(\"NUM_TightID_DEN_genTracks_eta_pt\")\n",
    "    h_SF_ISO_BC = f_SF_ISO_BC.Get(\"NUM_TightRelIso_DEN_TightIDandIPCut_eta_pt\")\n",
    "    h_SF_TRG_BC = f_SF_trg_BC.Get(\"IsoMu24_OR_IsoTkMu24_PtEtaBins/abseta_pt_ratio\")\n",
    "    h_SF_ID_G = f_SF_ID_G.Get(\"NUM_TightID_DEN_genTracks_eta_pt\")\n",
    "    h_SF_ISO_G = f_SF_ISO_G.Get(\"NUM_TightRelIso_DEN_TightIDandIPCut_eta_pt\")\n",
    "    h_SF_TRG_G = f_SF_trg_G.Get(\"IsoMu24_OR_IsoTkMu24_PtEtaBins/abseta_pt_ratio\")\n",
    "    '''\n",
    "    Get_Object_f_SF_ID_BC = f_SF_ID_BC.GetObject( \"NUM_TightID_DEN_genTracks_eta_pt\", h_SF_ID_BC )\n",
    "    Get_Object_f_SF_ISO_BC = f_SF_ID_BC.GetObject( \"NUM_TightID_DEN_genTracks_eta_pt\", h_SF_ISO_BC )\n",
    "    Get_Object_f_SF_trg_BC = f_SF_ID_BC.GetObject( \"NUM_TightID_DEN_genTracks_eta_pt\", h_SF_TRG_BC )\n",
    "    Get_Object_f_SF_ID_G = f_SF_ID_BC.GetObject( \"NUM_TightID_DEN_genTracks_eta_pt\", h_SF_ID_G )\n",
    "    Get_Object_f_SF_ISO_G = f_SF_ID_BC.GetObject( \"NUM_TightID_DEN_genTracks_eta_pt\", h_SF_ISO_G )\n",
    "    Get_Object_f_SF_trg_G = f_SF_ID_BC.GetObject( \"NUM_TightID_DEN_genTracks_eta_pt\", h_SF_TRG_G )\n",
    "    '''\n",
    "    # Extra Tracks Reweight\n",
    "    f_track_re = ROOT.TFile.Open( \"Extra_track_reweight.root\" )\n",
    "    f_track_re_ele = ROOT.TFile.Open( \"Extra_track_reweight_ele.root\" )\n",
    "    #h_track_re = ROOT.TH2D()\n",
    "    \n",
    "    #Get_Object_f_track_re = f_SF_ID_BC.GetObject( \"NUM_TightID_DEN_genTracks_eta_pt\", h_track_re )\n",
    "\n",
    "    \n",
    "    h_track_re = f_track_re.Get( \"h5\" )\n",
    "    #h_track_re_ele = f_track_re_ele.Get( \"h5\" )\n",
    "    \n",
    "    weigth_id_BC  = [] # For muon \n",
    "    weigth_iso_BC = [] # For muon\n",
    "    weigth_trg_BC = [] # For muon\n",
    "    weight_id_G = []   # For muon\n",
    "    weight_iso_G = []  # For muon\n",
    "    weight_trg_G = []  # For muon\n",
    "    \n",
    "    weigth_track_re = [] # For Extra Tracks\n",
    "    weigth_track_re_ele = [] # For Extra Tracks\n",
    "\n",
    "\n",
    "    for i in range( 0, len( DataSet ) ):\n",
    "        if [DataSet[:,9] < 120][0][i]:\n",
    "            weigth_id_BC.append( h_SF_ID_BC.GetBinContent( h_SF_ID_BC.GetXaxis().FindBin( DataSet[:,10][i] ), h_SF_ISO_BC.GetYaxis().FindBin( DataSet[:,9][i] ) ) )\n",
    "        else:\n",
    "            weigth_id_BC.append( h_SF_ID_BC.GetBinContent( h_SF_ID_BC.GetXaxis().FindBin( DataSet[:,10][i] ), h_SF_ISO_BC.GetYaxis().FindBin( 119 ) ) )\n",
    "       \n",
    "    \n",
    "    for i in range( 0, len( DataSet ) ):\n",
    "        if [ DataSet[:,9] < 120 ][0][i]:\n",
    "            weigth_iso_BC.append( h_SF_ISO_BC.GetBinContent( h_SF_ISO_BC.GetXaxis().FindBin( DataSet[:,10][i] ), h_SF_ISO_BC.GetYaxis().FindBin( DataSet[:,9][i] ) ) )\n",
    "        else:\n",
    "            weigth_iso_BC.append( h_SF_ISO_BC.GetBinContent( h_SF_ISO_BC.GetXaxis().FindBin( DataSet[:,10][i] ), h_SF_ISO_BC.GetYaxis().FindBin( 119 ) ) )\n",
    "   \n",
    "    for i in range( 0, len( DataSet ) ):\n",
    "        if [ DataSet[:,9] < 120 ][0][i]:\n",
    "            weight_id_G.append( h_SF_ID_G.GetBinContent( h_SF_ID_G.GetXaxis().FindBin( DataSet[:,10][i] ), h_SF_ID_G.GetYaxis().FindBin( DataSet[:,9][i] ) ) )\n",
    "        else:\n",
    "            weight_id_G.append( h_SF_ID_G.GetBinContent( h_SF_ID_G.GetXaxis().FindBin( DataSet[:,10][i] ), h_SF_ID_G.GetYaxis().FindBin( 119 ) ) )\n",
    "    \n",
    "    for i in range( 0, len( DataSet ) ):\n",
    "        if [ DataSet[:,9] < 120 ][0][i]:\n",
    "            weight_iso_G.append( h_SF_ISO_G.GetBinContent( h_SF_ISO_G.GetXaxis().FindBin( DataSet[:,10][i] ), h_SF_ISO_G.GetYaxis().FindBin( DataSet[:,9][i] ) ) )\n",
    "        else:\n",
    "            weight_iso_G.append( h_SF_ISO_G.GetBinContent( h_SF_ISO_G.GetXaxis().FindBin( DataSet[:,10][i] ), h_SF_ISO_G.GetYaxis().FindBin( 119 ) ) )\n",
    "\n",
    "        \n",
    "    for i in range( 0, len( DataSet ) ):\n",
    "        if [ DataSet[:,9] < 500 ][0][i]:\n",
    "            weigth_trg_BC.append( h_SF_TRG_BC.GetBinContent( h_SF_TRG_BC.GetXaxis().FindBin( DataSet[:,10][i] ), h_SF_TRG_BC.GetYaxis().FindBin( DataSet[:,9][i] ) ) )\n",
    "        else:\n",
    "            weigth_trg_BC.append( h_SF_TRG_BC.GetBinContent( h_SF_TRG_BC.GetXaxis().FindBin( DataSet[:,10][i] ), h_SF_TRG_BC.GetYaxis().FindBin( 499 ) ) )\n",
    "    \n",
    "    for i in range( 0, len( DataSet ) ):\n",
    "        if [ DataSet[:,9] < 500 ][0][i]:\n",
    "            weight_trg_G.append( h_SF_TRG_G.GetBinContent( h_SF_TRG_G.GetXaxis().FindBin( DataSet[:,10][i] ), h_SF_TRG_G.GetYaxis().FindBin( DataSet[:,9][i] ) ) )\n",
    "        else:\n",
    "            weight_trg_G.append( h_SF_TRG_G.GetBinContent( h_SF_TRG_G.GetXaxis().FindBin( DataSet[:,10][i] ), h_SF_TRG_G.GetYaxis().FindBin( 499 ) ) )\n",
    "                     \n",
    "        \n",
    "    for i in range( 0, len( DataSet ) ):\n",
    "        if [ DataSet[:,11] == 0 ][0][i]:\n",
    "            weigth_track_re.append( h_track_re.GetBinContent( h_track_re.GetXaxis().FindBin( 0.1 ) ) )\n",
    "            #weigth_track_re_ele.append( h_track_re_ele.GetBinContent(h_track_re_ele.GetXaxis().FindBin(0.1) ) )\n",
    "        else:\n",
    "            weigth_track_re.append( h_track_re.GetBinContent( h_track_re.GetXaxis().FindBin( DataSet[:,11][i] ) ) )\n",
    "            #weigth_track_re_ele.append( h_track_re_ele.GetBinContent(h_track_re_ele.GetXaxis().FindBin( DataSet[:,11][i] ) ) )\n",
    "            \n",
    "    weigth_id = np.array( weigth_id_BC )*(6.14/9.79) + np.array( weight_id_G )*(3.65/9.79)\n",
    "    weigth_iso = np.array( weigth_iso_BC )*(6.14/9.79) + np.array( weight_iso_G )*(3.65/9.79)\n",
    "    weigth_trg = np.array( weigth_trg_BC )*(6.14/9.79) + np.array( weight_trg_G )*(3.65/9.79)\n",
    "    \n",
    "    return weigth_id*weigth_iso*weigth_trg*weigth_track_re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amostras de Signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Normalização "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seção de Choque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_section_SM       = 40.41*0.17\n",
    "cross_section_ANOMALO1 = 166.1*0.17 \n",
    "cross_section_ANOMALO2 = 41.90*0.17\n",
    "cross_section_ANOMALO3 = 48.75*0.17\n",
    "cross_section_ANOMALO4 = 61.14*0.17\n",
    "cross_section_ANOMALO5 = 41.58*0.17\n",
    "cross_section_ANOMALO6 = 44.93*0.17\n",
    "cross_section_ANOMALO7 = 58.18*0.17 \n",
    "cross_section_ANOMALO8 = 150.3*0.17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Número de Eventos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_events_SM       = 35000\n",
    "number_events_ANOMALO1 = 35000\n",
    "number_events_ANOMALO2 = 35000\n",
    "number_events_ANOMALO3 = 35000\n",
    "number_events_ANOMALO4 = 35000\n",
    "number_events_ANOMALO5 = 35000\n",
    "number_events_ANOMALO6 = 35000\n",
    "number_events_ANOMALO7 = 35000\n",
    "number_events_ANOMALO8 = 35000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizacao dos eventos de SIGNAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_SM = ( cross_section_SM * Luminosidade ) / ( number_events_SM )\n",
    "norm_ANOMALO1 = ( cross_section_ANOMALO1 * Luminosidade ) / ( number_events_ANOMALO1 )\n",
    "norm_ANOMALO2 = ( cross_section_ANOMALO2 * Luminosidade ) / ( number_events_ANOMALO2 )\n",
    "norm_ANOMALO3 = ( cross_section_ANOMALO3 * Luminosidade ) / ( number_events_ANOMALO3 )\n",
    "norm_ANOMALO4 = ( cross_section_ANOMALO4 * Luminosidade ) / ( number_events_ANOMALO4 )\n",
    "norm_ANOMALO5 = ( cross_section_ANOMALO5 * Luminosidade ) / ( number_events_ANOMALO5 )\n",
    "norm_ANOMALO6 = ( cross_section_ANOMALO6 * Luminosidade ) / ( number_events_ANOMALO6 )\n",
    "norm_ANOMALO7 = ( cross_section_ANOMALO7 * Luminosidade ) / ( number_events_ANOMALO7 )\n",
    "norm_ANOMALO8 = ( cross_section_ANOMALO8 * Luminosidade ) / ( number_events_ANOMALO8 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Importando as amostras de Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SM = PATH + 'output-SM.h5'\n",
    "ANOMALO1 = PATH + 'output-ANOMALO1.h5'\n",
    "ANOMALO2 = PATH + 'output-ANOMALO2.h5'\n",
    "ANOMALO3 = PATH + 'output-ANOMALO3.h5'\n",
    "ANOMALO4 = PATH + 'output-ANOMALO4.h5'\n",
    "ANOMALO5 = PATH + 'output-ANOMALO5.h5'\n",
    "ANOMALO6 = PATH + 'output-ANOMALO6.h5'\n",
    "ANOMALO7 = PATH + 'output-ANOMALO7.h5'\n",
    "ANOMALO8 = PATH + 'output-ANOMALO8.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiRP Events ::  (31, 38)\n",
      "MultiRP Events ::  (386, 38)\n",
      "MultiRP Events ::  (45, 38)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-e3cbe47864a3>:8: RuntimeWarning: invalid value encountered in greater\n",
      "  array_cut = (array[:,0] > 600) & (array[:,1] > 200) & (array[:,2] > 2) & (array[:,3] > 2) & (array[:,4] > 200) & (array[:,5] < 2.4) & (array[:,7] < 0.6) & (array[:,8] > 40) & (array[:,9] > 53)  & (array[:,10] < 2.4) # Corte no xi1 e no xi2\n",
      "<ipython-input-4-e3cbe47864a3>:8: RuntimeWarning: invalid value encountered in less\n",
      "  array_cut = (array[:,0] > 600) & (array[:,1] > 200) & (array[:,2] > 2) & (array[:,3] > 2) & (array[:,4] > 200) & (array[:,5] < 2.4) & (array[:,7] < 0.6) & (array[:,8] > 40) & (array[:,9] > 53)  & (array[:,10] < 2.4) # Corte no xi1 e no xi2\n",
      "<ipython-input-4-e3cbe47864a3>:11: RuntimeWarning: invalid value encountered in greater\n",
      "  arrau_cut_xi = (DataSet_[:,14] > 0.04) & (DataSet_[:,15] > 0.04) & (DataSet_[:,14] < 0.111) & (DataSet_[:,15] < 0.138)\n",
      "<ipython-input-4-e3cbe47864a3>:11: RuntimeWarning: invalid value encountered in less\n",
      "  arrau_cut_xi = (DataSet_[:,14] > 0.04) & (DataSet_[:,15] > 0.04) & (DataSet_[:,14] < 0.111) & (DataSet_[:,15] < 0.138)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MultiRP Events ::  (111, 38)\n",
      "MultiRP Events ::  (151, 38)\n",
      "MultiRP Events ::  (48, 38)\n",
      "MultiRP Events ::  (76, 38)\n",
      "MultiRP Events ::  (164, 38)\n",
      "MultiRP Events ::  (401, 38)\n"
     ]
    }
   ],
   "source": [
    "SM =       open_file(SM)\n",
    "ANOMALO1 = open_file(ANOMALO1)\n",
    "ANOMALO2 = open_file(ANOMALO2)\n",
    "ANOMALO3 = open_file(ANOMALO3)\n",
    "ANOMALO4 = open_file(ANOMALO4)\n",
    "ANOMALO5 = open_file(ANOMALO5)\n",
    "ANOMALO6 = open_file(ANOMALO6)\n",
    "ANOMALO7 = open_file(ANOMALO7)\n",
    "ANOMALO8 = open_file(ANOMALO8)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "** numeração das colunas do numpy array ** ( para facilitar na hora de fazer os cortes )\n",
    "\n",
    "0  --> massa do WW\n",
    "1  --> Pt do W leptônico\n",
    "2  --> DeltaPhi entre W_hadrônico e W_leptônico\n",
    "3  --> DeltaPhi entre Jatos e o MET\n",
    "4  --> jetAK8_pt\n",
    "5  --> jetAK8_eta\n",
    "6  --> jetAK8_prunedMass\n",
    "7  --> jetAK8_tau21\n",
    "8  --> METPt\n",
    "9  --> muon_pt\n",
    "10 --> muon_eta\n",
    "11 --> ExtraTracks\n",
    "12 --> PUWeight\n",
    "13 --> Yww\n",
    "14 --> xi do proton 1\n",
    "15 --> xi do proton 2\n",
    "16 --> ângulo X 1\n",
    "17 --> ângulo X 2\n",
    "18 --> ângulo Y 1\n",
    "19 --> ângulo Y 2\n",
    "20 --> rpid 1\n",
    "21 --> rpid 2\n",
    "22 --> braço 1\n",
    "23 --> braço 2\n",
    "24 --> multirp 1\n",
    "25 --> multirp 2\n",
    "26 --> near_x 1\n",
    "27 --> near_x 2\n",
    "28 --> near_y 1\n",
    "29 --> near_y 2\n",
    "30 --> far_x 1\n",
    "31 --> far_x 2\n",
    "32 --> far_y 1\n",
    "33 --> far_y 2\n",
    "34 --> Mx\n",
    "35 --> Yx\n",
    "36 --> Mww/Mx\n",
    "37 --> Yww - Yx\n",
    "38 --> normalização\n",
    "39 --> weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenando os pesos no array dos eventos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_SM = np.array( [ norm_SM ]*len( SM ) ).reshape(-1,1)\n",
    "SM = np.concatenate( ( SM , weight_SM ) , axis = 1 )\n",
    "\n",
    "weight_ANOMALO1 = np.array( [ norm_ANOMALO1 ]*len( ANOMALO1 ) ).reshape(-1,1)\n",
    "ANOMALO1 = np.concatenate( ( ANOMALO1 , weight_ANOMALO1 ) , axis = 1 )\n",
    "\n",
    "weight_ANOMALO2 = np.array( [ norm_ANOMALO2 ]*len( ANOMALO2 ) ).reshape(-1,1)\n",
    "ANOMALO2 = np.concatenate( ( ANOMALO2 , weight_ANOMALO2 ) , axis = 1 )\n",
    "\n",
    "weight_ANOMALO3 = np.array( [ norm_ANOMALO3 ]*len( ANOMALO3 ) ).reshape(-1,1)\n",
    "ANOMALO3 = np.concatenate( ( ANOMALO3 , weight_ANOMALO3 ) , axis = 1 )\n",
    "\n",
    "weight_ANOMALO4 = np.array( [ norm_ANOMALO4 ]*len( ANOMALO4 ) ).reshape(-1,1)\n",
    "ANOMALO4 = np.concatenate( ( ANOMALO4 , weight_ANOMALO4 ) , axis = 1 )\n",
    "\n",
    "weight_ANOMALO5 = np.array( [ norm_ANOMALO5 ]*len( ANOMALO5 ) ).reshape(-1,1)\n",
    "ANOMALO5 = np.concatenate( ( ANOMALO5 , weight_ANOMALO5 ) , axis = 1 )\n",
    "\n",
    "weight_ANOMALO6 = np.array( [ norm_ANOMALO6 ]*len( ANOMALO6 ) ).reshape(-1,1)\n",
    "ANOMALO6 = np.concatenate( ( ANOMALO6 , weight_ANOMALO6 ) , axis = 1 )\n",
    "\n",
    "weight_ANOMALO7 = np.array( [ norm_ANOMALO7 ]*len( ANOMALO7 ) ).reshape(-1,1) \n",
    "ANOMALO7 = np.concatenate( ( ANOMALO7 , weight_ANOMALO7 ) , axis = 1 )\n",
    "\n",
    "weight_ANOMALO8 = np.array( [ norm_ANOMALO8 ]*len( ANOMALO8) ).reshape(-1,1)\n",
    "ANOMALO8 = np.concatenate( ( ANOMALO8 , weight_ANOMALO8 ) , axis = 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amostras de Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O estado final do sinal pode ser imitado por muitos processos do Modelo Padrão. o\n",
    "processos de background que são considerados na análise são listados aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\textbf{W+jatos}$: \n",
    "é o fundo principal. É produzido por fusão parton-parton com uma produção W ( $qg \\rightarrow  W q' $ ou $qq'  \\rightarrow W g$) onde o $W$ decai em um par lepton-neutrino e o parton(quark ou gluon) dá origem a um jato\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\textbf{ttbar}$: \n",
    "é o segundo fundo principal, já que o quark top sempre decai em um $W$ mais\n",
    "um quark adicional (> 99% sendo quark inferior), a produção ttbar dá origem a\n",
    "um processo com dois $W$. Também é produzido por fusão parton-parton\n",
    " ($q \\bar{q} \\rightarrow t\\bar{t}$ ou $gg \\rightarrow t\\bar{t}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\textbf{QCD}$: \n",
    "é um processo de multiplos jatos produzido por fusão parton-parton. As amostras QCD\n",
    "são gerados com um filtro para aceitar eventos com pelo menos um múon com $p_{T}> 5$ GeV.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\textbf{Drell-Yan}$:\n",
    "é um estado final de par de leptões produzido em uma fusão $q\\bar{q}$. O processo tem\n",
    "jatos adicionais da fragmentação do próton que podem imitar o sinal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\textbf{Single top}$:\n",
    "pode ser produzido de 3 maneiras diferentes: no canal t no $qb \\rightarrow qt$ espalhamento mediado por um W virtual.  no canal tW por um espalhamento de quark de gluon-bottom ($bg \\rightarrow  W t$). E no canal s, quando um espalhamento de quark-antiquark dá origem a um estado final top-anti-bottom ($q \\bar{q} \\rightarrow \\bar{b}t$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\textbf{WW,WZ,ZZ inclusivo}$:\n",
    "são processos são considerados como pano de fundo, mesmo com seus\n",
    "pequenas seções de choque porque são os processos do Modelo Padrão mais próximos da\n",
    "topologia de sinal. Eles também são produzidos por fusão parton-parton $q\\bar{q} \\rightarrow WW$, $q\\bar{q} \\rightarrow WZ$, $q\\bar{q} \\rightarrow ZZ$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Normalização "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seção de Choque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cross_section_TT = 831.7\n",
    "cross_section_inclusive_WZ = 10.73\n",
    "cross_section_inclusive_WW = 49.997\n",
    "cross_section_inclusive_ZZ = 3.28\n",
    "cross_section_ST_s_channel = 3.365\n",
    "cross_section_ST_t_channel_top = 136.02\n",
    "cross_section_ST_t_channel_antitop = 80.95\n",
    "cross_section_ST_tW_top= 35.85\n",
    "cross_section_ST_tW_antitop = 35.85\n",
    "cross_section_DYJetsToLL_Pt_100To250 = 83.12\n",
    "cross_section_DYJetsToLL_Pt_250To400 = 3.047\n",
    "cross_section_DYJetsToLL_Pt_400To650 = 0.3921 \n",
    "cross_section_DYJetsToLL_Pt_650ToInf = 0.0363\n",
    "cross_section_QCD_Pt_170to300 = 8654. \n",
    "cross_section_QCD_Pt_300to470 = 797.3\n",
    "cross_section_QCD_Pt_470to600 = 79.0\n",
    "cross_section_QCD_Pt_600to800 = 25.09\n",
    "cross_section_QCD_Pt_800to1000 = 4.7\n",
    "cross_section_QCD_Pt_1000toInf = 1.6\n",
    "cross_section_WJetsToLNu_Pt_100To250 = 677.82 \n",
    "cross_section_WJetsToLNu_Pt_250To400 = 24.083\n",
    "cross_section_WJetsToLNu_Pt_400To600 = 3.0563 \n",
    "cross_section_WJetsToLNu_Pt_600ToInf = 0.4602"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Número de Eventos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_events_TT = 76915549\n",
    "\n",
    "number_events_inclusive_WZ = 24311445\n",
    "number_events_inclusive_WW = 6655400 + 1999200\n",
    "number_events_inclusive_ZZ = 15061141 + 755866\n",
    "\n",
    "number_events_ST_s_channel = 1000000\n",
    "number_events_ST_t_channel_top = 43864048\n",
    "number_events_ST_t_channel_antitop = 38811017\n",
    "number_events_ST_tW_top = 6952830\n",
    "number_events_ST_tW_antitop = 6933094\n",
    "\n",
    "number_events_DYJetsToLL_Pt_100To250 =  2991815 + 2805972 + 2046961\n",
    "number_events_DYJetsToLL_Pt_250To400 =  594317 + 590806 + 423976\n",
    "number_events_DYJetsToLL_Pt_400To650 = 604038 + 589842 + 432056\n",
    "number_events_DYJetsToLL_Pt_650ToInf = 597526 + 430691\n",
    "\n",
    "number_events_QCD_Pt_170to300 = 19789673 + 7947159\n",
    "number_events_QCD_Pt_300to470 = 24605508 + 16462878 + 7937590\n",
    "number_events_QCD_Pt_470to600 = 9847664 + 5668793 + 3972819\n",
    "number_events_QCD_Pt_600to800 = 9928218 + 5971175 + 401013\n",
    "number_events_QCD_Pt_800to1000 = 9966149 + 6011849 + 3962749\n",
    "number_events_QCD_Pt_1000toInf = 9638102 + 3990117\n",
    "\n",
    "number_events_WJetsToLNu_Pt_100To250 = 10088599 + 9944879 \n",
    "number_events_WJetsToLNu_Pt_250To400 = 10021205 + 1001250 + 1000132\n",
    "number_events_WJetsToLNu_Pt_400To600 = 988234 + 951713\n",
    "number_events_WJetsToLNu_Pt_600ToInf = 985127 + 989482"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizacao dos eventos de BACKGROUND "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_TT = ( cross_section_TT * 1000 * Luminosidade ) / number_events_TT\n",
    "\n",
    "norm_inclusive_WZ = ( cross_section_inclusive_WZ * 1000 * Luminosidade ) / number_events_inclusive_WZ\n",
    "norm_inclusive_ZZ = ( cross_section_inclusive_ZZ * 1000 * Luminosidade ) / number_events_inclusive_ZZ\n",
    "norm_inclusive_WW = ( cross_section_inclusive_WW * 1000 * Luminosidade ) / number_events_inclusive_WW\n",
    "\n",
    "norm_ST_s_channel = ( cross_section_ST_s_channel * 1000 * Luminosidade ) / number_events_ST_s_channel\n",
    "norm_ST_t_channel_top = ( cross_section_ST_t_channel_top * 1000 * Luminosidade ) / number_events_ST_t_channel_top\n",
    "norm_ST_t_channel_antitop = ( cross_section_ST_t_channel_antitop * 1000 * Luminosidade) / number_events_ST_t_channel_antitop\n",
    "norm_ST_tW_antitop = ( cross_section_ST_tW_antitop * Luminosidade * 1000 ) / number_events_ST_tW_antitop\n",
    "norm_ST_tW_top = ( cross_section_ST_tW_top * 1000 * Luminosidade) / number_events_ST_tW_top\n",
    " \n",
    "norm_QCD_Pt_170to300  = ( cross_section_QCD_Pt_170to300 * 1000  * Luminosidade ) / ( number_events_QCD_Pt_170to300  )\n",
    "norm_QCD_Pt_300to470  = ( cross_section_QCD_Pt_300to470 * 1000  * Luminosidade ) / ( number_events_QCD_Pt_300to470  )\n",
    "norm_QCD_Pt_470to600  = ( cross_section_QCD_Pt_470to600 * 1000  * Luminosidade ) / ( number_events_QCD_Pt_470to600  )\n",
    "norm_QCD_Pt_600to800  = ( cross_section_QCD_Pt_600to800 * 1000  * Luminosidade ) / ( number_events_QCD_Pt_600to800  )\n",
    "norm_QCD_Pt_800to1000 = ( cross_section_QCD_Pt_800to1000 * 1000 * Luminosidade ) / ( number_events_QCD_Pt_800to1000 )\n",
    "norm_QCD_Pt_1000toInf = ( cross_section_QCD_Pt_1000toInf * 1000 * Luminosidade ) / ( number_events_QCD_Pt_1000toInf )\n",
    "\n",
    "norm_DYJetsToLL_Pt_100To250 = ( cross_section_DYJetsToLL_Pt_100To250 * 1000 * Luminosidade ) / ( number_events_DYJetsToLL_Pt_100To250 )\n",
    "norm_DYJetsToLL_Pt_250To400 = ( cross_section_DYJetsToLL_Pt_250To400 * 1000 * Luminosidade ) / ( number_events_DYJetsToLL_Pt_250To400 )\n",
    "norm_DYJetsToLL_Pt_400To650 = ( cross_section_DYJetsToLL_Pt_400To650 * 1000 * Luminosidade ) / ( number_events_DYJetsToLL_Pt_400To650 )\n",
    "norm_DYJetsToLL_Pt_650ToInf = ( cross_section_DYJetsToLL_Pt_650ToInf * 1000 * Luminosidade ) / ( number_events_DYJetsToLL_Pt_650ToInf )\n",
    "\n",
    "norm_WJetsToLNu_Pt_100To250 = ( cross_section_WJetsToLNu_Pt_100To250 * 1000 * Luminosidade ) / ( number_events_WJetsToLNu_Pt_100To250 )\n",
    "norm_WJetsToLNu_Pt_250To400 = ( cross_section_WJetsToLNu_Pt_250To400 * 1000 * Luminosidade ) / ( number_events_WJetsToLNu_Pt_250To400 )\n",
    "norm_WJetsToLNu_Pt_400To600 = ( cross_section_WJetsToLNu_Pt_400To600 * 1000 * Luminosidade ) / ( number_events_WJetsToLNu_Pt_400To600 )\n",
    "norm_WJetsToLNu_Pt_600ToInf = ( cross_section_WJetsToLNu_Pt_600ToInf * 1000 * Luminosidade ) / ( number_events_WJetsToLNu_Pt_600ToInf )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Importando as amostras de Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* DRELL YAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-e3cbe47864a3>:8: RuntimeWarning: invalid value encountered in greater\n",
      "  array_cut = (array[:,0] > 600) & (array[:,1] > 200) & (array[:,2] > 2) & (array[:,3] > 2) & (array[:,4] > 200) & (array[:,5] < 2.4) & (array[:,7] < 0.6) & (array[:,8] > 40) & (array[:,9] > 53)  & (array[:,10] < 2.4) # Corte no xi1 e no xi2\n",
      "<ipython-input-4-e3cbe47864a3>:8: RuntimeWarning: invalid value encountered in less\n",
      "  array_cut = (array[:,0] > 600) & (array[:,1] > 200) & (array[:,2] > 2) & (array[:,3] > 2) & (array[:,4] > 200) & (array[:,5] < 2.4) & (array[:,7] < 0.6) & (array[:,8] > 40) & (array[:,9] > 53)  & (array[:,10] < 2.4) # Corte no xi1 e no xi2\n",
      "<ipython-input-4-e3cbe47864a3>:11: RuntimeWarning: invalid value encountered in greater\n",
      "  arrau_cut_xi = (DataSet_[:,14] > 0.04) & (DataSet_[:,15] > 0.04) & (DataSet_[:,14] < 0.111) & (DataSet_[:,15] < 0.138)\n",
      "<ipython-input-4-e3cbe47864a3>:11: RuntimeWarning: invalid value encountered in less\n",
      "  arrau_cut_xi = (DataSet_[:,14] > 0.04) & (DataSet_[:,15] > 0.04) & (DataSet_[:,14] < 0.111) & (DataSet_[:,15] < 0.138)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiRP Events ::  (459, 30)\n",
      "MultiRP Events ::  (514, 30)\n",
      "MultiRP Events ::  (338, 30)\n",
      "MultiRP Events ::  (4493, 30)\n",
      "MultiRP Events ::  (4527, 30)\n",
      "MultiRP Events ::  (3210, 30)\n",
      "MultiRP Events ::  (10673, 30)\n",
      "MultiRP Events ::  (10460, 30)\n",
      "MultiRP Events ::  (7821, 30)\n",
      "MultiRP Events ::  (11336, 30)\n",
      "MultiRP Events ::  (8086, 30)\n"
     ]
    }
   ],
   "source": [
    "# Pt entre 100 e 250 GeV\n",
    "DY_100_250_2 = PATH + 'output-DY_100_250_2.h5'\n",
    "DY_100_250_3 = PATH + 'output-DY_100_250_3.h5'\n",
    "DY_100_250_4 = PATH + 'output-DY_100_250_4.h5'\n",
    "\n",
    "DY_100_250 = np.concatenate(  ( open_file( DY_100_250_2 ), \n",
    "                                open_file( DY_100_250_3 ), \n",
    "                                open_file( DY_100_250_4 ) )  , axis = 0 ) \n",
    "\n",
    "weight_DY_100_250 = np.array( [ norm_DYJetsToLL_Pt_100To250 ]*len( DY_100_250 ) ).reshape(-1,1)\n",
    "\n",
    "DY_100_250 = np.concatenate( ( DY_100_250 , weight_DY_100_250 ) , axis = 1 )\n",
    "\n",
    "# Miguel, fazer o caso acima para todos os arquivos, tanto back quanto signal\n",
    "\n",
    "# Pt entre 250 e 400 GeV\n",
    "DY_250_400_2 = PATH + 'output-DY_250_400_2.h5'\n",
    "DY_250_400_3 = PATH + 'output-DY_250_400_3.h5'\n",
    "DY_250_400_4 = PATH + 'output-DY_250_400_4.h5'\n",
    "\n",
    "DY_250_400 = np.concatenate(  ( open_file( DY_250_400_2 ), \n",
    "                                open_file( DY_250_400_3 ), \n",
    "                                open_file( DY_250_400_4 ) )  , axis = 0 ) \n",
    "\n",
    "weight_DY_250_400 = np.array( [ norm_DYJetsToLL_Pt_250To400 ]*len( DY_250_400 ) ).reshape(-1,1)\n",
    "\n",
    "DY_250_400 = np.concatenate( ( DY_250_400 , weight_DY_250_400 ) , axis = 1 )\n",
    "\n",
    "# Pt entre 400 e 650 GeV\n",
    "DY_400_650_1 = PATH + 'output-DY_400_650_1.h5'\n",
    "DY_400_650_2 = PATH + 'output-DY_400_650_2.h5'\n",
    "DY_400_650_3 = PATH + 'output-DY_400_650_3.h5'\n",
    "\n",
    "DY_400_650 = np.concatenate(  ( open_file( DY_400_650_1 ), \n",
    "                                open_file( DY_400_650_2 ), \n",
    "                                open_file( DY_400_650_3 ) )  , axis = 0 ) \n",
    "\n",
    "weight_DY_400_650 = np.array( [ norm_DYJetsToLL_Pt_400To650 ]*len( DY_400_650 ) ).reshape(-1,1)\n",
    "\n",
    "DY_400_650 = np.concatenate( ( DY_400_650 , weight_DY_400_650 ) , axis = 1 )\n",
    "\n",
    "# Pt entre 650 e infinito GeV\n",
    "DY_650_INF_1 = PATH + 'output-DY_650_INF_1.h5'\n",
    "DY_650_INF_2 = PATH + 'output-DY_650_INF_2.h5'\n",
    "\n",
    "DY_650_INF = np.concatenate(  ( open_file( DY_650_INF_1 ), \n",
    "                                open_file( DY_650_INF_2 ) )  , axis = 0 ) \n",
    "\n",
    "weight_DY_650_INF = np.array( [ norm_DYJetsToLL_Pt_650ToInf ]*len( DY_650_INF ) ).reshape(-1,1)\n",
    "\n",
    "DY_650_INF = np.concatenate( ( DY_650_INF , weight_DY_650_INF ) , axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenando todas as constribuições de Pt para o Drell-Yan\n",
    "Drell_Yan = np.concatenate( ( DY_100_250 , DY_250_400 , DY_400_650 , DY_650_INF ) , axis = 0  ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* QCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-e3cbe47864a3>:8: RuntimeWarning: invalid value encountered in greater\n",
      "  array_cut = (array[:,0] > 600) & (array[:,1] > 200) & (array[:,2] > 2) & (array[:,3] > 2) & (array[:,4] > 200) & (array[:,5] < 2.4) & (array[:,7] < 0.6) & (array[:,8] > 40) & (array[:,9] > 53)  & (array[:,10] < 2.4) # Corte no xi1 e no xi2\n",
      "<ipython-input-4-e3cbe47864a3>:8: RuntimeWarning: invalid value encountered in less\n",
      "  array_cut = (array[:,0] > 600) & (array[:,1] > 200) & (array[:,2] > 2) & (array[:,3] > 2) & (array[:,4] > 200) & (array[:,5] < 2.4) & (array[:,7] < 0.6) & (array[:,8] > 40) & (array[:,9] > 53)  & (array[:,10] < 2.4) # Corte no xi1 e no xi2\n",
      "<ipython-input-4-e3cbe47864a3>:11: RuntimeWarning: invalid value encountered in greater\n",
      "  arrau_cut_xi = (DataSet_[:,14] > 0.04) & (DataSet_[:,15] > 0.04) & (DataSet_[:,14] < 0.111) & (DataSet_[:,15] < 0.138)\n",
      "<ipython-input-4-e3cbe47864a3>:11: RuntimeWarning: invalid value encountered in less\n",
      "  arrau_cut_xi = (DataSet_[:,14] > 0.04) & (DataSet_[:,15] > 0.04) & (DataSet_[:,14] < 0.111) & (DataSet_[:,15] < 0.138)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiRP Events ::  (166, 30)\n",
      "MultiRP Events ::  (48, 30)\n",
      "MultiRP Events ::  (1957, 30)\n",
      "MultiRP Events ::  (1482, 30)\n",
      "MultiRP Events ::  (608, 30)\n",
      "MultiRP Events ::  (1709, 30)\n",
      "MultiRP Events ::  (1024, 30)\n",
      "MultiRP Events ::  (642, 30)\n",
      "MultiRP Events ::  (2408, 30)\n",
      "MultiRP Events ::  (1466, 30)\n",
      "MultiRP Events ::  (953, 30)\n",
      "MultiRP Events ::  (3421, 30)\n",
      "MultiRP Events ::  (1975, 30)\n",
      "MultiRP Events ::  (1339, 30)\n",
      "MultiRP Events ::  (4347, 30)\n",
      "MultiRP Events ::  (1741, 30)\n"
     ]
    }
   ],
   "source": [
    "# Pt entre 170 e 300 GeV\n",
    "QCD_170_300_1 = PATH + 'output-QCD_170_300_1.h5'\n",
    "QCD_170_300_3 = PATH + 'output-QCD_170_300_3.h5'\n",
    "\n",
    "QCD_170_300 = np.concatenate(  ( open_file( QCD_170_300_1 ), \n",
    "                                 open_file( QCD_170_300_3 ) )  , axis = 0 ) \n",
    "\n",
    "weight_QCD_170_300 = np.array( [ norm_QCD_Pt_170to300 ]*len( QCD_170_300 ) ).reshape(-1,1)\n",
    "\n",
    "QCD_170_300 = np.concatenate( ( QCD_170_300 , weight_QCD_170_300 ) , axis = 1 )\n",
    "\n",
    "# Pt entre 300 e 470 GeV\n",
    "QCD_300_470_1 = PATH + 'output-QCD_300_470_1.h5'\n",
    "QCD_300_470_2 = PATH + 'output-QCD_300_470_2.h5'\n",
    "QCD_300_470_3 = PATH + 'output-QCD_300_470_3.h5'\n",
    "\n",
    "QCD_300_470 = np.concatenate(  ( open_file( QCD_300_470_1 ), \n",
    "                                 open_file( QCD_300_470_2 ),\n",
    "                                 open_file( QCD_300_470_3 ) )  , axis = 0 ) \n",
    "\n",
    "weight_QCD_300_470 = np.array( [ norm_QCD_Pt_300to470 ]*len( QCD_300_470 ) ).reshape(-1,1)\n",
    "\n",
    "QCD_300_470 = np.concatenate( ( QCD_300_470 , weight_QCD_300_470 ) , axis = 1 )\n",
    "\n",
    "# Pt entre 470 e 600 GeV\n",
    "QCD_470_600_1 = PATH + 'output-QCD_470_600_1.h5'\n",
    "QCD_470_600_2 = PATH + 'output-QCD_470_600_2.h5'\n",
    "QCD_470_600_3 = PATH + 'output-QCD_470_600_3.h5'\n",
    "\n",
    "QCD_470_600 = np.concatenate(  ( open_file( QCD_470_600_1 ), \n",
    "                                 open_file( QCD_470_600_2 ),\n",
    "                                 open_file( QCD_470_600_3 ) )  , axis = 0 ) \n",
    "\n",
    "weight_QCD_470_600 = np.array( [ norm_QCD_Pt_470to600 ]*len( QCD_470_600 ) ).reshape(-1,1)\n",
    "\n",
    "QCD_470_600 = np.concatenate( ( QCD_470_600 , weight_QCD_470_600 ) , axis = 1 )\n",
    "\n",
    "# Pt entre 600 e 800 GeV\n",
    "QCD_600_800_1 = PATH + 'output-QCD_600_800_1.h5'\n",
    "QCD_600_800_2 = PATH + 'output-QCD_600_800_2.h5'\n",
    "QCD_600_800_3 = PATH + 'output-QCD_600_800_3.h5'\n",
    "\n",
    "QCD_600_800 = np.concatenate(  ( open_file( QCD_600_800_1 ), \n",
    "                                 open_file( QCD_600_800_2 ),\n",
    "                                 open_file( QCD_600_800_3 ) )  , axis = 0 ) \n",
    "\n",
    "weight_QCD_600_800 = np.array( [ norm_QCD_Pt_600to800 ]*len( QCD_600_800 ) ).reshape(-1,1)\n",
    "\n",
    "QCD_600_800 = np.concatenate( ( QCD_600_800 , weight_QCD_600_800 ) , axis = 1 )\n",
    "\n",
    "# Pt entre 800 e 1000 GeV\n",
    "QCD_800_1000_1 = PATH + 'output-QCD_800_1000_1.h5'\n",
    "QCD_800_1000_2 = PATH + 'output-QCD_800_1000_2.h5'\n",
    "QCD_800_1000_3 = PATH + 'output-QCD_800_1000_3.h5'\n",
    "\n",
    "QCD_800_1000 = np.concatenate(  ( open_file( QCD_800_1000_1 ), \n",
    "                                  open_file( QCD_800_1000_2 ),\n",
    "                                  open_file( QCD_800_1000_3 ) )  , axis = 0 ) \n",
    "\n",
    "weight_QCD_800_1000 = np.array( [ norm_QCD_Pt_800to1000 ]*len( QCD_800_1000 ) ).reshape(-1,1)\n",
    "\n",
    "QCD_800_1000 = np.concatenate( ( QCD_800_1000 , weight_QCD_800_1000 ) , axis = 1 )\n",
    "\n",
    "# Pt entre 1000 e infinito GeV\n",
    "QCD_1000_inf_1 = PATH +'output-QCD_1000_inf_1.h5'\n",
    "QCD_1000_inf_2 = PATH +'output-QCD_1000_inf_2.h5'\n",
    "\n",
    "QCD_1000_inf = np.concatenate(  ( open_file( QCD_1000_inf_1 ), \n",
    "                                  open_file( QCD_1000_inf_2 ) )  , axis = 0 ) \n",
    "\n",
    "weight_QCD_1000_inf = np.array( [ norm_QCD_Pt_1000toInf ]*len( QCD_1000_inf ) ).reshape(-1,1)\n",
    "\n",
    "QCD_1000_inf = np.concatenate( ( QCD_1000_inf , weight_QCD_1000_inf ) , axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenando todas as constribuições de Pt para o QCD\n",
    "QCD = np.concatenate( ( QCD_170_300 , QCD_300_470 , QCD_470_600 , QCD_600_800 , QCD_800_1000 , QCD_1000_inf ) , axis = 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SINGLE ANTI-TOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-e3cbe47864a3>:8: RuntimeWarning: invalid value encountered in greater\n",
      "  array_cut = (array[:,0] > 600) & (array[:,1] > 200) & (array[:,2] > 2) & (array[:,3] > 2) & (array[:,4] > 200) & (array[:,5] < 2.4) & (array[:,7] < 0.6) & (array[:,8] > 40) & (array[:,9] > 53)  & (array[:,10] < 2.4) # Corte no xi1 e no xi2\n",
      "<ipython-input-4-e3cbe47864a3>:8: RuntimeWarning: invalid value encountered in less\n",
      "  array_cut = (array[:,0] > 600) & (array[:,1] > 200) & (array[:,2] > 2) & (array[:,3] > 2) & (array[:,4] > 200) & (array[:,5] < 2.4) & (array[:,7] < 0.6) & (array[:,8] > 40) & (array[:,9] > 53)  & (array[:,10] < 2.4) # Corte no xi1 e no xi2\n",
      "<ipython-input-4-e3cbe47864a3>:11: RuntimeWarning: invalid value encountered in greater\n",
      "  arrau_cut_xi = (DataSet_[:,14] > 0.04) & (DataSet_[:,15] > 0.04) & (DataSet_[:,14] < 0.111) & (DataSet_[:,15] < 0.138)\n",
      "<ipython-input-4-e3cbe47864a3>:11: RuntimeWarning: invalid value encountered in less\n",
      "  arrau_cut_xi = (DataSet_[:,14] > 0.04) & (DataSet_[:,15] > 0.04) & (DataSet_[:,14] < 0.111) & (DataSet_[:,15] < 0.138)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiRP Events ::  (9473, 30)\n"
     ]
    }
   ],
   "source": [
    "Single_Antitop = PATH + 'output-Single_Antitop.h5'\n",
    "file_Single_Antitop = open_file(Single_Antitop)\n",
    "\n",
    "weight_ST_tW_antitop = np.array( [ norm_ST_tW_antitop ]*len( file_Single_Antitop ) ).reshape(-1,1)\n",
    "Single_Antitop = np.concatenate( ( file_Single_Antitop , weight_ST_tW_antitop ) , axis = 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SINGLE ANTI-TOP tCHANEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-e3cbe47864a3>:8: RuntimeWarning: invalid value encountered in greater\n",
      "  array_cut = (array[:,0] > 600) & (array[:,1] > 200) & (array[:,2] > 2) & (array[:,3] > 2) & (array[:,4] > 200) & (array[:,5] < 2.4) & (array[:,7] < 0.6) & (array[:,8] > 40) & (array[:,9] > 53)  & (array[:,10] < 2.4) # Corte no xi1 e no xi2\n",
      "<ipython-input-4-e3cbe47864a3>:8: RuntimeWarning: invalid value encountered in less\n",
      "  array_cut = (array[:,0] > 600) & (array[:,1] > 200) & (array[:,2] > 2) & (array[:,3] > 2) & (array[:,4] > 200) & (array[:,5] < 2.4) & (array[:,7] < 0.6) & (array[:,8] > 40) & (array[:,9] > 53)  & (array[:,10] < 2.4) # Corte no xi1 e no xi2\n",
      "<ipython-input-4-e3cbe47864a3>:11: RuntimeWarning: invalid value encountered in greater\n",
      "  arrau_cut_xi = (DataSet_[:,14] > 0.04) & (DataSet_[:,15] > 0.04) & (DataSet_[:,14] < 0.111) & (DataSet_[:,15] < 0.138)\n",
      "<ipython-input-4-e3cbe47864a3>:11: RuntimeWarning: invalid value encountered in less\n",
      "  arrau_cut_xi = (DataSet_[:,14] > 0.04) & (DataSet_[:,15] > 0.04) & (DataSet_[:,14] < 0.111) & (DataSet_[:,15] < 0.138)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiRP Events ::  (2105, 30)\n"
     ]
    }
   ],
   "source": [
    "Single_Antitop_tChannel = PATH + 'output-Single_Antitop_tChannel.h5'\n",
    "file_Single_Antitop_tChannel = open_file(Single_Antitop_tChannel)\n",
    "\n",
    "weight_Antitop_tChannel = np.array( [ norm_ST_t_channel_antitop ]*len( file_Single_Antitop_tChannel ) ).reshape(-1,1)\n",
    "Single_Antitop_tChannel = np.concatenate( ( file_Single_Antitop_tChannel , weight_Antitop_tChannel ) , axis = 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SINGLE TOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-e3cbe47864a3>:8: RuntimeWarning: invalid value encountered in greater\n",
      "  array_cut = (array[:,0] > 600) & (array[:,1] > 200) & (array[:,2] > 2) & (array[:,3] > 2) & (array[:,4] > 200) & (array[:,5] < 2.4) & (array[:,7] < 0.6) & (array[:,8] > 40) & (array[:,9] > 53)  & (array[:,10] < 2.4) # Corte no xi1 e no xi2\n",
      "<ipython-input-4-e3cbe47864a3>:8: RuntimeWarning: invalid value encountered in less\n",
      "  array_cut = (array[:,0] > 600) & (array[:,1] > 200) & (array[:,2] > 2) & (array[:,3] > 2) & (array[:,4] > 200) & (array[:,5] < 2.4) & (array[:,7] < 0.6) & (array[:,8] > 40) & (array[:,9] > 53)  & (array[:,10] < 2.4) # Corte no xi1 e no xi2\n",
      "<ipython-input-4-e3cbe47864a3>:11: RuntimeWarning: invalid value encountered in greater\n",
      "  arrau_cut_xi = (DataSet_[:,14] > 0.04) & (DataSet_[:,15] > 0.04) & (DataSet_[:,14] < 0.111) & (DataSet_[:,15] < 0.138)\n",
      "<ipython-input-4-e3cbe47864a3>:11: RuntimeWarning: invalid value encountered in less\n",
      "  arrau_cut_xi = (DataSet_[:,14] > 0.04) & (DataSet_[:,15] > 0.04) & (DataSet_[:,14] < 0.111) & (DataSet_[:,15] < 0.138)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiRP Events ::  (9819, 30)\n"
     ]
    }
   ],
   "source": [
    "Single_Top = PATH + 'output-Single_Top.h5'\n",
    "file_Single_Top = open_file(Single_Top)\n",
    "\n",
    "weight_Single_Top = np.array( [ norm_ST_tW_top ]*len( file_Single_Top ) ).reshape(-1,1)\n",
    "Single_Top = np.concatenate( ( file_Single_Top , weight_Single_Top ) , axis = 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SINGLE TOP sCHANNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-e3cbe47864a3>:8: RuntimeWarning: invalid value encountered in greater\n",
      "  array_cut = (array[:,0] > 600) & (array[:,1] > 200) & (array[:,2] > 2) & (array[:,3] > 2) & (array[:,4] > 200) & (array[:,5] < 2.4) & (array[:,7] < 0.6) & (array[:,8] > 40) & (array[:,9] > 53)  & (array[:,10] < 2.4) # Corte no xi1 e no xi2\n",
      "<ipython-input-4-e3cbe47864a3>:8: RuntimeWarning: invalid value encountered in less\n",
      "  array_cut = (array[:,0] > 600) & (array[:,1] > 200) & (array[:,2] > 2) & (array[:,3] > 2) & (array[:,4] > 200) & (array[:,5] < 2.4) & (array[:,7] < 0.6) & (array[:,8] > 40) & (array[:,9] > 53)  & (array[:,10] < 2.4) # Corte no xi1 e no xi2\n",
      "<ipython-input-4-e3cbe47864a3>:11: RuntimeWarning: invalid value encountered in greater\n",
      "  arrau_cut_xi = (DataSet_[:,14] > 0.04) & (DataSet_[:,15] > 0.04) & (DataSet_[:,14] < 0.111) & (DataSet_[:,15] < 0.138)\n",
      "<ipython-input-4-e3cbe47864a3>:11: RuntimeWarning: invalid value encountered in less\n",
      "  arrau_cut_xi = (DataSet_[:,14] > 0.04) & (DataSet_[:,15] > 0.04) & (DataSet_[:,14] < 0.111) & (DataSet_[:,15] < 0.138)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiRP Events ::  (289, 30)\n"
     ]
    }
   ],
   "source": [
    "Single_Top_sChanel = PATH + 'output-Single_Top_sChanel.h5'\n",
    "file_Single_Top_sChanel = open_file(Single_Top_sChanel)\n",
    "\n",
    "weight_Single_Top_sChanel = np.array( [ norm_ST_s_channel ]*len( file_Single_Top_sChanel ) ).reshape(-1,1)\n",
    "Single_Top_sChanel = np.concatenate( ( file_Single_Top_sChanel , weight_Single_Top_sChanel ) , axis = 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SINGLE TOP tCHANNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-e3cbe47864a3>:8: RuntimeWarning: invalid value encountered in greater\n",
      "  array_cut = (array[:,0] > 600) & (array[:,1] > 200) & (array[:,2] > 2) & (array[:,3] > 2) & (array[:,4] > 200) & (array[:,5] < 2.4) & (array[:,7] < 0.6) & (array[:,8] > 40) & (array[:,9] > 53)  & (array[:,10] < 2.4) # Corte no xi1 e no xi2\n",
      "<ipython-input-4-e3cbe47864a3>:8: RuntimeWarning: invalid value encountered in less\n",
      "  array_cut = (array[:,0] > 600) & (array[:,1] > 200) & (array[:,2] > 2) & (array[:,3] > 2) & (array[:,4] > 200) & (array[:,5] < 2.4) & (array[:,7] < 0.6) & (array[:,8] > 40) & (array[:,9] > 53)  & (array[:,10] < 2.4) # Corte no xi1 e no xi2\n",
      "<ipython-input-4-e3cbe47864a3>:11: RuntimeWarning: invalid value encountered in greater\n",
      "  arrau_cut_xi = (DataSet_[:,14] > 0.04) & (DataSet_[:,15] > 0.04) & (DataSet_[:,14] < 0.111) & (DataSet_[:,15] < 0.138)\n",
      "<ipython-input-4-e3cbe47864a3>:11: RuntimeWarning: invalid value encountered in less\n",
      "  arrau_cut_xi = (DataSet_[:,14] > 0.04) & (DataSet_[:,15] > 0.04) & (DataSet_[:,14] < 0.111) & (DataSet_[:,15] < 0.138)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiRP Events ::  (2791, 30)\n"
     ]
    }
   ],
   "source": [
    "Single_Top_tChannel = PATH + 'output-Single_Top_tChannel.h5'\n",
    "file_Single_Top_tChannel = open_file(Single_Top_tChannel)\n",
    "\n",
    "weight_Single_Top_tChannel = np.array( [ norm_ST_t_channel_top ]*len( file_Single_Top_tChannel ) ).reshape(-1,1)\n",
    "Single_Top_tChannel = np.concatenate( ( file_Single_Top_tChannel , weight_Single_Top_tChannel ) , axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_top = np.concatenate( ( Single_Top_tChannel, \n",
    "                               Single_Top_sChanel , \n",
    "                               Single_Top , \n",
    "                               Single_Antitop_tChannel , \n",
    "                               Single_Antitop) , axis = 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TTBAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TTbar = PATH + 'output-ttbar.h5'\n",
    "file_TTbar = open_file(TTbar)\n",
    "\n",
    "weight_Single_Top_sChanel = np.array( [ norm_TT ]*len( file_TTbar ) ).reshape(-1,1)\n",
    "TTbar = np.concatenate( ( file_TTbar , weight_Single_Top_sChanel ) , axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TTbar.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* W + JETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pt entre 100 e 250 GeV\n",
    "\n",
    "WJets_100_250_2 = PATH + 'output-WJets_100_250_2.h5'\n",
    "WJets_100_250_3 = PATH + 'output-WJets_100_250_3.h5'\n",
    "\n",
    "WJets_100_250 = np.concatenate(  ( open_file( WJets_100_250_2 ), \n",
    "                                   open_file( WJets_100_250_3 ) )  , axis = 0 ) \n",
    "\n",
    "weight_WJets_100_250 = np.array( [ norm_WJetsToLNu_Pt_100To250 ]*len( WJets_100_250 ) ).reshape(-1,1)\n",
    "\n",
    "WJets_100_250 = np.concatenate( ( WJets_100_250 , weight_WJets_100_250 ) , axis = 1 )\n",
    "\n",
    "\n",
    "# Pt entre 250 e 400 GeV \n",
    "\n",
    "WJets_250_400_1 = PATH +'output-WJets_250_400_1.h5'\n",
    "WJets_250_400_2 = PATH +'output-WJets_250_400_2.h5'\n",
    "WJets_250_400_3 = PATH +'output-WJets_250_400_3.h5'\n",
    "\n",
    "WJets_250_400 = np.concatenate(  ( open_file( WJets_250_400_1 ), \n",
    "                                   open_file( WJets_250_400_2 ),\n",
    "                                  (open_file( WJets_250_400_3 ) ))  , axis = 0 ) \n",
    "\n",
    "weight_WJets_250_400 = np.array( [ norm_WJetsToLNu_Pt_250To400 ]*len( WJets_250_400 ) ).reshape(-1,1)\n",
    "\n",
    "WJets_250_400 = np.concatenate( ( WJets_250_400 , weight_WJets_250_400 ) , axis = 1 )\n",
    "\n",
    "# Pt entre 400 e 600 GeV\n",
    "WJets_400_600_1 = PATH + 'output-WJets_400_600_1.h5'\n",
    "WJets_400_600_2 = PATH + 'output-WJets_400_600_2.h5'\n",
    "\n",
    "WJets_400_600 = np.concatenate(  ( open_file( WJets_400_600_1 ), \n",
    "                                   open_file( WJets_400_600_2 ) )  , axis = 0 ) \n",
    "\n",
    "weight_WJets_400_600 = np.array( [ norm_WJetsToLNu_Pt_400To600 ]*len( WJets_400_600 ) ).reshape(-1,1)\n",
    "\n",
    "WJets_400_600 = np.concatenate( ( WJets_400_600 , weight_WJets_400_600 ) , axis = 1 )\n",
    "\n",
    "# Pt entre 600 e infinito GeV\n",
    "WJets_600_inf_1 = PATH + 'output-WJets_600_inf_1.h5'\n",
    "WJets_600_inf_2 = PATH + 'output-WJets_600_inf_2.h5'\n",
    "\n",
    "WJets_600_inf = np.concatenate(  ( open_file( WJets_600_inf_1 ), \n",
    "                                   open_file( WJets_600_inf_2 ) )  , axis = 0 ) \n",
    "\n",
    "weight_WJets_600_inf = np.array( [ norm_WJetsToLNu_Pt_600ToInf ]*len( WJets_600_inf ) ).reshape(-1,1)\n",
    "\n",
    "WJets_600_inf = np.concatenate( ( WJets_600_inf , weight_WJets_600_inf ) , axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenando todas as constribuições de Pt para o W + Jets\n",
    "WJets = np.concatenate( ( WJets_100_250 , WJets_250_400 , WJets_400_600 , WJets_600_inf ) , axis = 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* INCLUSIVO WW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WW_1 = PATH + 'output-WW1.h5'\n",
    "WW_2 = PATH + 'output-WW2.h5'\n",
    "\n",
    "WW = np.concatenate(  ( open_file( WW_1 ), \n",
    "                        open_file( WW_2 ) )  , axis = 0 ) \n",
    "\n",
    "weight_WW = np.array( [ norm_inclusive_WW ]*len( WW ) ).reshape(-1,1)\n",
    "WW = np.concatenate( ( WW , weight_WW ) , axis = 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* INCLUSIVO WZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WZ = PATH + 'output-WZ.h5'\n",
    "file_WZ = open_file(WZ)\n",
    "\n",
    "weight_WZ = np.array( [ norm_inclusive_WZ ]*len( file_WZ ) ).reshape(-1,1)\n",
    "WZ = np.concatenate( ( file_WZ , weight_WZ ) , axis = 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* INCLUSIVO ZZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZZ_1 = PATH + 'output-ZZ1.h5'\n",
    "ZZ_2 = PATH + 'output-ZZ2.h5'\n",
    "\n",
    "ZZ = np.concatenate(  ( open_file( ZZ_1 ), \n",
    "                        open_file( ZZ_2 ) )  , axis = 0 ) \n",
    "\n",
    "weight_ZZ = np.array( [ norm_inclusive_ZZ ]*len( ZZ ) ).reshape(-1,1)\n",
    "ZZ = np.concatenate( ( ZZ , weight_ZZ ) , axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VV_inclusivo = np.concatenate( ( WW , WZ , ZZ ) , axis = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VV_inclusivo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dados - 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data Era B ','\\n')\n",
    "Data_B = open_file( PATH + 'output-Data_B.h5')\n",
    "print('\\n')\n",
    "\n",
    "print('Data Era C \\n')\n",
    "Data_C = open_file( PATH + 'output-Data_C.h5')\n",
    "print('\\n')\n",
    "\n",
    "print('Data Era G \\n')\n",
    "Data_G = open_file( PATH + 'output-Data_G.h5')\n",
    "print('\\n',Data_G.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dadinhos_reais = np.concatenate( ( Data_B , Data_C ,  Data_G ) , axis = 0 )\n",
    "pd.DataFrame( Dadinhos_reais )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''label_back = [ r'$t\\bar{t}}$',  'W+Jatos','QCD', '(WW, WZ, ZZ) Inclusivo', 'Single-Top', 'Drell-Yan', ]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''label_signal = [\n",
    "r'WWCEP $\\alpha_{C}^{W}/\\Lambda^{2}=0.0$ (SM)',\n",
    "r'WWCEP $\\alpha_{C}^{W}/\\Lambda^{2}=2 \\times 10^{-5}$',\n",
    "r'WWCEP $\\alpha_{C}^{W}/\\Lambda^{2}=8 \\times 10^{-6}$',\n",
    "r'WWCEP $\\alpha_{0}^{W}/\\Lambda^{2} = 0.5 \\times 10^{-6} $',\n",
    "r'WWCEP $\\alpha_{0}^{W}/\\Lambda^{2} = 5.0 \\times 10^{-6} $'\n",
    "          ]'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set de Sinal apenas MultiRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiRP_SM = np.concatenate( ( SM, EfficienciesStudies(SM).reshape(-1,1) * EffiProtonSignal(SM).reshape(-1,1) * SM[:,12].reshape(-1,1) * SM[:,38].reshape(-1,1) ), axis = 1 ) \n",
    "multiRP_ANOMALO1 = np.concatenate( ( ANOMALO1, EfficienciesStudies(ANOMALO1).reshape(-1,1) * EffiProtonSignal(ANOMALO1).reshape(-1,1) * ANOMALO1[:,12].reshape(-1,1) * ANOMALO1[:,38].reshape(-1,1)), axis = 1 ) \n",
    "multiRP_ANOMALO2 = np.concatenate( ( ANOMALO2, EfficienciesStudies(ANOMALO2).reshape(-1,1) * EffiProtonSignal(ANOMALO2).reshape(-1,1) * ANOMALO2[:,12].reshape(-1,1) * ANOMALO2[:,38].reshape(-1,1)), axis = 1 ) \n",
    "multiRP_ANOMALO3 = np.concatenate( ( ANOMALO3, EfficienciesStudies(ANOMALO3).reshape(-1,1) * EffiProtonSignal(ANOMALO3).reshape(-1,1) * ANOMALO3[:,12].reshape(-1,1) * ANOMALO3[:,38].reshape(-1,1)), axis = 1 ) \n",
    "multiRP_ANOMALO4 = np.concatenate( ( ANOMALO4, EfficienciesStudies(ANOMALO4).reshape(-1,1) * EffiProtonSignal(ANOMALO4).reshape(-1,1) * ANOMALO4[:,12].reshape(-1,1) * ANOMALO4[:,38].reshape(-1,1)), axis = 1 ) \n",
    "multiRP_ANOMALO5 = np.concatenate( ( ANOMALO5, EfficienciesStudies(ANOMALO5).reshape(-1,1) * EffiProtonSignal(ANOMALO5).reshape(-1,1) * ANOMALO5[:,12].reshape(-1,1) * ANOMALO5[:,38].reshape(-1,1)), axis = 1 ) \n",
    "multiRP_ANOMALO6 = np.concatenate( ( ANOMALO6, EfficienciesStudies(ANOMALO6).reshape(-1,1) * EffiProtonSignal(ANOMALO6).reshape(-1,1) * ANOMALO6[:,12].reshape(-1,1) * ANOMALO6[:,38].reshape(-1,1)), axis = 1 ) \n",
    "multiRP_ANOMALO7 = np.concatenate( ( ANOMALO7, EfficienciesStudies(ANOMALO7).reshape(-1,1) * EffiProtonSignal(ANOMALO7).reshape(-1,1) * ANOMALO7[:,12].reshape(-1,1) * ANOMALO7[:,38].reshape(-1,1)), axis = 1 ) \n",
    "multiRP_ANOMALO8 = np.concatenate( ( ANOMALO8, EfficienciesStudies(ANOMALO8).reshape(-1,1) * EffiProtonSignal(ANOMALO8).reshape(-1,1) * ANOMALO8[:,12].reshape(-1,1) * ANOMALO8[:,38].reshape(-1,1)), axis = 1 ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_Signal = ['Mww', 'Pt_W_lep', 'dPhi_Whad_Wlep', 'dPhi_jatos_MET', 'jetAK8_pt','jetAK8_eta', 'jetAK8_prunedMass',\n",
    "'jetAK8_tau21', 'METPt', 'muon_pt', 'muon_eta', 'ExtraTracks', 'PUWeight', 'Yww', 'xi1', 'xi2', 'angulo_X_1','angulo_X_2',\n",
    "'angulo_Y_1', 'angulo_Y_2', 'rpid_1', 'rpid_2', 'arm1', 'arm2', 'ismultirp_1','ismultirp_2', 'near_x1','near_x1',\n",
    "'near_y1', 'near_y2', 'far_x1','far_x1','far_y1', 'far_y2','Mx', 'Yx', 'Mww/Mx', 'Yww_Yx', 'Norm','weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame_multiRP_SM = pd.DataFrame( multiRP_SM, columns = columns_Signal )\n",
    "DataFrame_multiRP_ANOMALO1 = pd.DataFrame( multiRP_ANOMALO1, columns = columns_Signal )\n",
    "DataFrame_multiRP_ANOMALO2 = pd.DataFrame( multiRP_ANOMALO2, columns = columns_Signal )\n",
    "DataFrame_multiRP_ANOMALO3 = pd.DataFrame( multiRP_ANOMALO3, columns = columns_Signal )\n",
    "DataFrame_multiRP_ANOMALO4 = pd.DataFrame( multiRP_ANOMALO4, columns = columns_Signal )\n",
    "DataFrame_multiRP_ANOMALO5 = pd.DataFrame( multiRP_ANOMALO5, columns = columns_Signal )\n",
    "DataFrame_multiRP_ANOMALO6 = pd.DataFrame( multiRP_ANOMALO6, columns = columns_Signal )\n",
    "DataFrame_multiRP_ANOMALO7 = pd.DataFrame( multiRP_ANOMALO7, columns = columns_Signal )\n",
    "DataFrame_multiRP_ANOMALO8 = pd.DataFrame( multiRP_ANOMALO8, columns = columns_Signal )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set de Background apenas MultiRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiRP_Drell_Yan = np.concatenate(  (Drell_Yan ,  Drell_Yan[:,30].reshape(-1,1) * Drell_Yan[:,12].reshape(-1,1)  ), axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiRP_QCD = np.concatenate(  (QCD ,  QCD[:,30].reshape(-1,1) * QCD[:,12].reshape(-1,1)  ), axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiRP_single_top = np.concatenate(  (single_top ,  single_top[:,30].reshape(-1,1) * single_top[:,12].reshape(-1,1)  ), axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiRP_TTbar = np.concatenate(  (TTbar , TTbar[:,30].reshape(-1,1) * TTbar[:,12].reshape(-1,1)  ), axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiRP_WJets = np.concatenate(  (WJets , WJets[:,30].reshape(-1,1) * WJets[:,12].reshape(-1,1) ), axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiRP_VV_inclusivo = np.concatenate(  (VV_inclusivo , VV_inclusivo[:,30].reshape(-1,1) * VV_inclusivo[:,12].reshape(-1,1)  ), axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_MC = ['Mww', 'Pt_W_lep', 'dPhi_Whad_Wlep', 'dPhi_jatos_MET', 'jetAK8_pt','jetAK8_eta', 'jetAK8_prunedMass',\n",
    "'jetAK8_tau21', 'METPt', 'muon_pt', 'muon_eta', 'ExtraTracks', 'PUWeight', 'Yww', 'xi1', 'xi2', 'angulo_X_1','angulo_X_2',\n",
    "'angulo_Y_1', 'angulo_Y_2', 'rpid_1', 'rpid_2', 'arm1', 'arm2', 'ismultirp_1','ismultirp_2','Mx', 'Yx', \n",
    "'Mww/Mx', 'Yww_Yx', 'Norm','weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame_multiRP_WJets = pd.DataFrame( multiRP_WJets, columns = columns_MC )\n",
    "DataFrame_multiRP_Drell_Yan = pd.DataFrame( multiRP_Drell_Yan, columns = columns_MC )\n",
    "DataFrame_multiRP_QCD = pd.DataFrame( multiRP_QCD, columns = columns_MC )\n",
    "DataFrame_multiRP_single_top = pd.DataFrame( multiRP_single_top, columns = columns_MC )\n",
    "DataFrame_multiRP_TTbar = pd.DataFrame( multiRP_TTbar, columns = columns_MC )\n",
    "DataFrame_multiRP_VV_inclusivo = pd.DataFrame( multiRP_VV_inclusivo, columns = columns_MC )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_back_multirp = pd.concat( [ DataFrame_multiRP_WJets, DataFrame_multiRP_Drell_Yan, DataFrame_multiRP_QCD, \n",
    "                                          DataFrame_multiRP_single_top, DataFrame_multiRP_TTbar, DataFrame_multiRP_VV_inclusivo ], axis = 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set de dados contendo apenas MultiRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_Data = ['Mww', 'Pt_W_lep', 'dPhi_Whad_Wlep', 'dPhi_jatos_MET', 'jetAK8_pt','jetAK8_eta', 'jetAK8_prunedMass',\n",
    "'jetAK8_tau21', 'METPt', 'muon_pt', 'muon_eta', 'ExtraTracks', 'PUWeight' ,'Yww', 'xi1', 'xi2', 'angulo_X_1','angulo_X_2',\n",
    "'angulo_Y_1', 'angulo_Y_2', 'rpid_1', 'rpid_2', 'arm1', 'arm2', 'ismultirp_1','ismultirp_2','Mx', 'Yx', \n",
    "'Mww/Mx', 'Yww_Yx', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_dados_multirp = pd.DataFrame( Dadinhos_reais, columns = columns_Data )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando arquivos únicos em .h5 de signal, background e dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salve_dataset( df, label ):\n",
    "    with h5py.File( label + '.h5', 'w') as f:\n",
    "        dset = f.create_dataset( 'dados', data = df )\n",
    "    return dset   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_columns_MC = ['Mww', 'Pt_W_lep', 'dPhi_Whad_Wlep', 'dPhi_jatos_MET', 'jetAK8_pt','jetAK8_eta', 'jetAK8_prunedMass',\n",
    "'jetAK8_tau21', 'METPt', 'muon_pt', 'muon_eta', 'ExtraTracks', 'PUWeight', 'Yww', 'xi1', 'xi2', 'Mx', 'Yx', \n",
    "'Mww/Mx', 'Yww_Yx', 'weight']\n",
    "select_columns_Data = ['Mww', 'Pt_W_lep', 'dPhi_Whad_Wlep', 'dPhi_jatos_MET', 'jetAK8_pt','jetAK8_eta', 'jetAK8_prunedMass',\n",
    "'jetAK8_tau21', 'METPt', 'muon_pt', 'muon_eta', 'ExtraTracks', 'PUWeight', 'Yww', 'xi1', 'xi2','Mx', 'Yx', \n",
    "'Mww/Mx', 'Yww_Yx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_set_back_multirp[select_columns_MC].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salve_dataset(DataFrame_data_set_back_multirp[select_columns_MC] , 'DataSet_back_multiRP')\n",
    "\n",
    "salve_dataset(data_set_dados_multirp[select_columns_Data], pwd_effi + 'DataSet_dados_multiRP_AllCuts')\n",
    "\n",
    "salve_dataset(DataFrame_multiRP_Drell_Yan[select_columns_MC], pwd_effi + 'DataSet_multiRP_DrellYan_AllCuts')\n",
    "salve_dataset(DataFrame_multiRP_QCD[select_columns_MC], pwd_effi + 'DataSet_multiRP_QCD_AllCuts')\n",
    "salve_dataset(DataFrame_multiRP_single_top[select_columns_MC], pwd_effi + 'DataSet_multiRP_single_top_AllCuts')\n",
    "salve_dataset(DataFrame_multiRP_TTbar[select_columns_MC], pwd_effi + 'DataSet_multiRP_TTbar_AllCuts')\n",
    "salve_dataset(DataFrame_multiRP_WJets[select_columns_MC], pwd_effi + 'DataSet_multiRP_WJets_AllCuts')\n",
    "salve_dataset(DataFrame_multiRP_VV_inclusivo[select_columns_MC], pwd_effi + 'DataSet_multiRP_VV_inclusivo_AllCuts\n",
    "salve_dataset(DataFrame_multiRP_SM[select_columns_MC], pwd_effi + 'DataSet_SM_multiRP_AllCuts')\n",
    "salve_dataset(DataFrame_multiRP_ANOMALO1[select_columns_MC], pwd_effi + 'DataSet_ANOMALO1_multiRP_AllCuts')\n",
    "salve_dataset(DataFrame_multiRP_ANOMALO2[select_columns_MC],pwd_effi +  'DataSet_ANOMALO2_multiRP_AllCuts')\n",
    "salve_dataset(DataFrame_multiRP_ANOMALO3[select_columns_MC], pwd_effi + 'DataSet_ANOMALO3_multiRP_AllCuts')\n",
    "salve_dataset(DataFrame_multiRP_ANOMALO4[select_columns_MC], pwd_effi + 'DataSet_ANOMALO4_multiRP_AllCuts')\n",
    "salve_dataset(DataFrame_multiRP_ANOMALO5[select_columns_MC],pwd_effi +  'DataSet_ANOMALO5_multiRP_AllCuts')\n",
    "salve_dataset(DataFrame_multiRP_ANOMALO6[select_columns_MC],pwd_effi +  'DataSet_ANOMALO6_multiRP_AllCuts')\n",
    "salve_dataset(DataFrame_multiRP_ANOMALO7[select_columns_MC],pwd_effi +  'DataSet_ANOMALO7_multiRP_AllCuts')\n",
    "salve_dataset(DataFrame_multiRP_ANOMALO8[select_columns_MC],pwd_effi +  'DataSet_ANOMALO8_multiRP_AllCuts')\n",
    "\n",
    "#salve_dataset(data_set_back_multirp[select_columns_MC], pwd_effi + 'DataSet_back_multiRP')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
